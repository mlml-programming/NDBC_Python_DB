{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Integrating Python and MySQL for Data Retrieval and Storage</h3>\n",
    "<hr/>\n",
    "<p>\n",
    "The purpose of this notebook is to present a simple but real world example of using Python to access remote data sources and perform Extract, Transform, and Load (ETL) processes to write this data into a relational database.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we import the modules we will need\n",
    "import pymysql.cursors  # Our MySQL connector\n",
    "import pandas as pd # Our data manipulator - love this module\n",
    "import configparser as cfp # A useful way to make multipurpose scripts that can be customized later\n",
    "from datetime import datetime as dt # A module for creating date and time objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we will use our config parser and MySQL connector to open a connection to the database\n",
    "con=cfp.ConfigParser()\n",
    "con.read('/home/ryan/Python_Scripts/NDBC/config.ini') # This is a nifty way to store \n",
    "                                                      # connection parameters\n",
    "my_host=con['LOCALDB']['host']                                    \n",
    "my_port=int(con['LOCALDB']['port'])\n",
    "my_user=con['LOCALDB']['user']\n",
    "my_passwd=con['LOCALDB']['passwd']\n",
    "my_db=con['LOCALDB']['db']\n",
    "conn=pymysql.connect(host=my_host,port=my_port,user=my_user,passwd=my_passwd,\n",
    "                   db=my_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we build out some of the useful functions I know we will need.  It is not uncommon\n",
    "# to wind up building these parts later as you build out your code but since we need these\n",
    "# functions defined before we call them we will put them first.\n",
    "\n",
    "# Building in fucntionality to replace old names with the correct ones (as of 2014)\n",
    "def NDBCNames(oldname):\n",
    "    namedict={  #old    #new\n",
    "                'YYYY':'YY',\n",
    "                '#YY':'YY',\n",
    "                'WD':'WDIR',\n",
    "                'DIR':'WDIR',\n",
    "                'SPD':'WSPD',\n",
    "                'GSP':'GST',\n",
    "                'GNM':'GTIME',\n",
    "                'BAR':'PRES',\n",
    "                'BARO':'PRES',\n",
    "                'H0':'WVHT',\n",
    "                'DOMPD':'DPD',\n",
    "                'AVP':'APD',\n",
    "                'SRAD':'SWRAD',\n",
    "                'SRAD2':'SWRAD',\n",
    "                'LRAD':'LWRAD',\n",
    "                'LRAD1':'LWRAD'\n",
    "                }\n",
    "    if oldname in namedict:\n",
    "        return namedict[oldname]\n",
    "    else:\n",
    "        return oldname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function for getting the standard meteorological data for NDBC weather buoys\n",
    "# It accepts a database cursor, station id, year and/or month for which data is desired\n",
    "def getData(cursor,station,year,month):\n",
    "    base_url = 'http://www.ndbc.noaa.gov/view_text_file.php?filename={}'.format(station)\n",
    "    if month==0:\n",
    "        target=base_url+'h'+str(year)+'.txt.gz&dir=data/historical/stdmet/'\n",
    "    elif year==0:\n",
    "        tm=dt(this_year,month,1)\n",
    "        target=base_url+str(month)+str(this_year)+'.txt.gz&dir=data/stdmet/'+tm.strftime('%b')+'/'\n",
    "    else:\n",
    "        print('Not sure what you meant to do here but this is weird')\n",
    "    # okay now that we have built our url that should point toward the text data file\n",
    "    # let's grad that data file\n",
    "        \n",
    "    # we are trainwrecking in 2007 when (at least for station 46042)\n",
    "    # NOAA started adding a second line to the header with the units\n",
    "    # for each measurement.  It would be nice to capture this somewhere\n",
    "    # in our DB but obviously it cannot be part of the numerical data.\n",
    "    # Perhaps an additional table?\n",
    "    try:\n",
    "        my_d=pd.read_csv(target,header=0, engine='python',sep=\"\\s+\")\n",
    "    except:\n",
    "        if month==0:\n",
    "            print(\"Year \" +  str(year) + \" is not available\")\n",
    "        elif year==0:\n",
    "            print(\"Month \" + str(month) + \" is not available\")\n",
    "        return pd.DataFrame() # in order to properly evaluate the result we need to return an empty data frame...kind of wasteful memory wise but it works\n",
    "    # Now let's get those pesky year, month, day, and\n",
    "    # hour columns into a Timestamp\n",
    "    # first we get the columns with our datetime info\n",
    "    if my_d.iloc[0][0]==\"#yr\":\n",
    "        my_d=insertUnits(cursor,my_d)\n",
    "    cols=list(my_d.columns)\n",
    "    if 'mm' in cols:\n",
    "        cols=cols[0:cols.index('mm')+1]\n",
    "        my_d.set_index(keys=cols,inplace=True)\n",
    "    else:\n",
    "        cols=cols[0:cols.index('hh')+1]\n",
    "        my_d.set_index(keys=cols,inplace=True)\n",
    "    my_dt=my_d.index.values\n",
    "    dtime=[]\n",
    "    for i in my_dt:\n",
    "        if len(str(i[0]))==2:\n",
    "            Y=i[0]+1900\n",
    "        else:\n",
    "            Y=i[0]\n",
    "        if len(cols)==5:\n",
    "            strtime=dt(int(Y),int(i[1]),int(i[2]),int(i[3]),int(i[4])).isoformat()\n",
    "        else:\n",
    "            strtime=dt(Y,i[1],i[2],i[3]).isoformat()\n",
    "        dtime.append(strtime)\n",
    "    my_d.index=dtime\n",
    "    # Huzzah, we have our datetime strings as our index!  Since\n",
    "    # it is ISO 8601 compliant this should be easily loaded into\n",
    "    # a MySQL DB.  Now let's handle those bad data flags\n",
    "    cols=list(my_d.columns) # we need to redo this to account for indexing\n",
    "    # AFTER CAREFUL CONSIDERATION IT APPEARS TO ME THAT DEALING WITH BAD DATA\n",
    "    # FLAGS WOULD BE EASIER DONE ONCE THE DATA HAS BEEN LOADED INTO THE DATABASE\n",
    "    # THEREFORE I WILL SKIP THIS SECTION AND IMPLEMENT A BAD DATA FLAG PROTOCOL\n",
    "    # LATER ON, AFTER INSERTING THE RECORDS.\n",
    "    newcols=[];\n",
    "    for col in cols:\n",
    "        newcols.append(NDBCNames(col))\n",
    "\n",
    "    my_d.columns=newcols\n",
    "    my_d.fillna(999.0, inplace=True)\n",
    "    return my_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertStdMet(station,cursor,data):\n",
    "    # This function takes in a station id, database cursor and an array of data.  At present\n",
    "    # it assumes the data is a pandas dataaframe with the datetime value as the index\n",
    "    # It may eventually be modified to be more flexible.  With the parameters\n",
    "    # passed in, it goes row by row and builds an INSERT INTO SQL statement\n",
    "    # that assumes each row in the data array represents a new record to be\n",
    "    # added.\n",
    "    fields=list(data.columns) # if our table has been constructed properly, these column names should map to the fields in the data table\n",
    "    # Building the SQL string\n",
    "    strSQL1='REPLACE INTO std_met (station_id,date_time,'\n",
    "    strSQL2='VALUES (%s,%s,'\n",
    "    for f in fields:\n",
    "        strSQL1+=f+','\n",
    "        strSQL2+='%s,'\n",
    "    # trimming the last comma\n",
    "    strSQL1=strSQL1[:-1]\n",
    "    strSQL2=strSQL2[:-1]\n",
    "    strSQL1+=\") \" + strSQL2 + \")\"\n",
    "    # Okay, now we have our SQL string.  Now we need to build the list of tuples\n",
    "    # that will be passed along with it to the .executemany() function.\n",
    "    tuplist=[]\n",
    "    for i in range(len(data)):\n",
    "        r=data.iloc[i][:]\n",
    "        datatup=(station,r.name)\n",
    "        for f in r:\n",
    "            datatup+=(f,)\n",
    "        tuplist.append(datatup)\n",
    "    cursor.executemany(strSQL1,tuplist)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertUnits(cursor,data):\n",
    "    # This function is designed to check whether or not the first line of the \n",
    "    # pandas data frame passed in contains additional string information, usually\n",
    "    # the units for the parameters measured.  If so it will insert those units\n",
    "    # into the units table in our database\n",
    "    r=data.iloc[0][:]\n",
    "    if isinstance(r[0],str): # if we have a string we assume r represents the units\n",
    "        cols=list(data.columns) # getting our list of columns\n",
    "        strSQL=\"REPLACE INTO units (parameter, unit) VALUES (%s,%s)\"\n",
    "        tuplist=[]\n",
    "        if 'mm' in cols:\n",
    "            start_index=cols.index('mm')+1\n",
    "        else:\n",
    "            start_index=cols.index('hh')+1\n",
    "        for col in cols[start_index:]:\n",
    "            datatup=(col,r[col])\n",
    "            tuplist.append(datatup)\n",
    "        cursor.executemany(strSQL,tuplist)\n",
    "        data = data.iloc[1:][:]\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2000 is not available\n",
      "Year 2001 is not available\n",
      "Year 2002 is not available\n",
      "Year 2003 is not available\n",
      "Year 2004 is not available\n",
      "Year 2005 is not available\n",
      "Year 2006 is not available\n",
      "Year 2007 is not available\n",
      "Year 2008 is not available\n",
      "Year 2009 is not available\n",
      "Year 2010 is not available\n",
      "Year 2011 is not available\n",
      "Year 2012 is not available\n",
      "Year 2013 is not available\n",
      "Year 2014 is not available\n",
      "Year 2015 is not available\n",
      "Year 2016 is not available\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    conn.commit()\n",
    "    sql= \"SELECT station_id FROM ndbc_stations\"\n",
    "    cur.execute(sql)sql=\"REPLACE INTO `ndbc_stations` (`station_id`,) VALUES(%s)\"\n",
    "    cur.execute(sql,('46042'))\n",
    "    \n",
    "    stations=cur.fetchall()\n",
    "    for station in stations:\n",
    "        for id in station:\n",
    "            for y in range(2000,2017):\n",
    "                stdmet=getData(cur,id,y,0)\n",
    "                if not stdmet.empty:\n",
    "                    insertStdMet(station,cur,stdmet)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur=conn.cursor()\n",
    "cur.execute('SELECT `station_id` FROM ndbc_stations')\n",
    "stations=cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('46042',),)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46042\n"
     ]
    }
   ],
   "source": [
    "for station in stations:\n",
    "    for id in station:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2015 is not available\n"
     ]
    }
   ],
   "source": [
    "stdmet=getData('46042',cur,2015,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.timedelta(hours=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
